{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting the duration of power outages\n",
    "\n",
    "**Name(s)**: Zihan Liu\n",
    "\n",
    "**Website Link**: https://anananan116.github.io/US_Power_Outage_Analysis_model/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:36:28.652554Z",
     "start_time": "2019-10-31T23:36:27.180520Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import plotly.express as px\n",
    "pd.options.plotting.backend = 'plotly'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Framing the Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Problem\n",
    "\n",
    "### Objective\n",
    "- **Predict the Duration of Power Outages**\n",
    "\n",
    "### Type\n",
    "- **Regression**\n",
    "  - The target variable, the duration of the power outage, is continuous.\n",
    "\n",
    "### Response Variable (Target)\n",
    "- `OUTAGE.DURATION`\n",
    "  - This is chosen as it directly indicates the length of the power interruption. It could be useful to power service companies to get a estimate of the duration of the power outage for their customers before it is fixed.\n",
    "\n",
    "### Features Considered\n",
    "- `U.S._STATE`\n",
    "  - Geographic location can be a significant factor due to different infrastructure and weather patterns.\n",
    "- `ANOMALY.LEVEL`, `CLIMATE.CATEGORY`\n",
    "  - These indicate climate conditions, crucial for predicting weather-related outages.\n",
    "- `CAUSE.CATEGORY`, `CAUSE.CATEGORY.DETAIL`\n",
    "  - Understanding the cause of the outage helps in estimating duration.\n",
    "- `CUSTOMERS.AFFECTED`\n",
    "  - The number of customers affected might correlate with the severity and duration of the outage.\n",
    "- `RES.PRICE`\n",
    "  - Residential price as an indirect indicator of infrastructure quality.\n",
    "- `SEASON`\n",
    "  - Different seasons have unique patterns impacting outage durations.\n",
    "\n",
    "- All features are known at the time of the power outage, making them relevant for real-time predictions.\n",
    "- Utility companies typically have access to this information (cause, affected customers, climate conditions) when an outage occurs.\n",
    "\n",
    "### Metric for Model Evaluation\n",
    "- **Primary Metric**: Mean Absolute Error (MAE)\n",
    "  - Chosen for its clear representation of average prediction error magnitude.\n",
    "  - RMSE or MSE could be considered, but they emphasize larger errors more which could be caused by the large amount of outliers in this power outage dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:36:28.657068Z",
     "start_time": "2019-10-31T23:36:28.654650Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|    | U.S._STATE   |   ANOMALY.LEVEL | CLIMATE.CATEGORY   | CAUSE.CATEGORY   | CAUSE.CATEGORY.DETAIL   |   OUTAGE.DURATION |   CUSTOMERS.AFFECTED |   RES.PRICE | SEASON   |\n",
      "|---:|:-------------|----------------:|:-------------------|:-----------------|:------------------------|------------------:|---------------------:|------------:|:---------|\n",
      "|  0 | Minnesota    |            -0.3 | normal             | severe weather   | nan                     |              3060 |                70000 |       11.6  | Summer   |\n",
      "|  2 | Minnesota    |            -1.5 | cold               | severe weather   | heavy wind              |              3000 |                70000 |       10.87 | Fall     |\n",
      "|  3 | Minnesota    |            -0.1 | normal             | severe weather   | thunderstorm            |              2550 |                68200 |       11.79 | Summer   |\n",
      "|  4 | Minnesota    |             1.2 | warm               | severe weather   | nan                     |              1740 |               250000 |       13.07 | Summer   |\n",
      "|  5 | Minnesota    |            -1.4 | cold               | severe weather   | winter storm            |              1860 |                60000 |       10.63 | Fall     |\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_excel('outage.xlsx').drop(['variables', 'OBS'], axis = 1)\n",
    "variable_names = [\n",
    "    \"MONTH\",\n",
    "    \"U.S._STATE\",\n",
    "    \"ANOMALY.LEVEL\",\n",
    "    \"CLIMATE.CATEGORY\",\n",
    "    \"CAUSE.CATEGORY\",\n",
    "    \"CAUSE.CATEGORY.DETAIL\",\n",
    "    \"OUTAGE.DURATION\",\n",
    "    \"CUSTOMERS.AFFECTED\",\n",
    "    \"RES.PRICE\"\n",
    "]\n",
    "df_cleaned = df[variable_names]\n",
    "df_cleaned = df_cleaned[pd.notna(df_cleaned['MONTH'])]\n",
    "def map_month_to_season(month):\n",
    "    month = int(month)  \n",
    "    if month in [12, 1, 2]:\n",
    "        return 'Winter'\n",
    "    elif month in [3, 4, 5]:\n",
    "        return 'Spring'\n",
    "    elif month in [6, 7, 8]:\n",
    "        return 'Summer'\n",
    "    else:\n",
    "        return 'Fall'\n",
    "\n",
    "df_cleaned['SEASON'] = df_cleaned['MONTH'].apply(map_month_to_season)\n",
    "df_cleaned['SERIOUSNESS'] = ((df_cleaned['OUTAGE.DURATION'] > 500) & (df_cleaned['CUSTOMERS.AFFECTED'] > 1000))\n",
    "df_cleaned = df_cleaned[df_cleaned['SERIOUSNESS']]\n",
    "df_cleaned = df_cleaned.drop('SERIOUSNESS', axis = 1)\n",
    "df_cleaned = df_cleaned.drop('MONTH', axis = 1)\n",
    "print(df_cleaned.head().to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Linear Regression Model Description\n",
    "\n",
    "We developed a baseline linear regression model focusing on predicting the duration of power outages. This model incorporated two quantitative features: `SEASON`(norminal) and `CUSTOMERS.AFFECTED`(quantitive). These features were selected based on their availability and presumed relevance to the prediction task. One-hot encoding was used to encode SEASON variable. And StandardScaler is used for the quatitive variable(CUSTOMERS.AFFECTED).\n",
    "\n",
    "### Model Performance\n",
    "\n",
    "The model's performance was evaluated using the Mean Absolute Error (MAE). It yielded an MAE of 2901 on the training set and 2427 on the test set. These high MAE values suggest a significant deviation between the model's predictions and the actual outage durations. The duration is recorded as number of minutes, thus the average error of this model is about 50 hours. Given the context of power outages, this level of error indicates that the model's predictive accuracy is relatively low.\n",
    "\n",
    "### Evaluation and Conclusion\n",
    "\n",
    "The current linear regression model appears inadequate for accurately predicting power outage durations. The use of only two features and the simplistic nature of a linear regression model limit its capability to capture the complex dynamics of power outage durations. These durations are likely influenced by various factors, including but not limited to environmental conditions and infrastructure, which are not adequately represented in the current model. To enhance predictive accuracy, it would be prudent to consider a broader range of features and explore more sophisticated modeling approaches that can capture non-linear relationships and interactions among variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2901.4410621361826, 2427.9062386845453)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_cleaned[['SEASON', 'CUSTOMERS.AFFECTED']]\n",
    "y = df_cleaned['OUTAGE.DURATION']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('transformer', ColumnTransformer([\n",
    "        ('one_hot_encoder', OneHotEncoder(), ['SEASON'])\n",
    "    ], remainder='passthrough')),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = pipeline.predict(X_train)\n",
    "y_test_pred = pipeline.predict(X_test)\n",
    "\n",
    "mae_train = mean_absolute_error(y_train, y_train_pred)\n",
    "mae_test = mean_absolute_error(y_test, y_test_pred) if len(y_test) > 0 else None\n",
    "\n",
    "mae_train, mae_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Model Development and Evaluation\n",
    "\n",
    "In developing my final model, I placed significant emphasis on the selection and engineering of features. I incorporated a mix of categorical variables - `U.S._STATE`, `CLIMATE.CATEGORY`, `CAUSE.CATEGORY`, `CAUSE.CATEGORY.DETAIL`, and `SEASON` - and numerical features like `ANOMALY.LEVEL`, `CUSTOMERS.AFFECTED`, and `RES.PRICE`. My rationale was rooted in the intrinsic relevance of these features to the phenomenon of power outages. For instance, the specific state reflects varying infrastructure and weather conditions, while the cause and climate category directly correlate with outage durations. These features were chosen to capture the broad spectrum of factors impacting power outages, aiming for a more accurate and nuanced predictive model.\n",
    "\n",
    "- `U.S._STATE`\n",
    "  - Geographic location can be a significant factor due to different infrastructure and weather patterns.\n",
    "- `ANOMALY.LEVEL`, `CLIMATE.CATEGORY`\n",
    "  - These indicate climate conditions, crucial for predicting weather-related outages.\n",
    "- `CAUSE.CATEGORY`, `CAUSE.CATEGORY.DETAIL`\n",
    "  - Understanding the cause of the outage helps in estimating duration.\n",
    "- `CUSTOMERS.AFFECTED`\n",
    "  - The number of customers affected might correlate with the severity and duration of the outage.\n",
    "- `RES.PRICE`\n",
    "  - Residential price as an indirect indicator of infrastructure quality.\n",
    "- `SEASON`\n",
    "  - Different seasons have unique patterns impacting outage durations.\n",
    "\n",
    "The RandomForestRegressor was the chosen algorithm for its proficiency in handling complex, non-linear data interactions and its ensemble learning approach, which is effective against overfitting. The best performing hyperparameters in my model were `n_estimators=100` and `max_depth=20`, identified through a systematic GridSearchCV process. This process tested combinations of `n_estimators` (10, 50, 100) and `max_depth` (None, 10, 20, 30), crucial for defining the forest structure. The choice of a higher number of estimators and unrestricted tree depth was aimed at capturing detailed patterns in the data while maintaining computational efficiency.\n",
    "\n",
    "The performance of my final model, as indicated by a lower Mean Absolute Error on both training and test sets, marked a notable improvement over the baseline model. This enhancement is attributed to the comprehensive feature set, which offered a deeper insight into the dynamics of power outages, and the optimized RandomForestRegressor, capable of effectively learning from this diverse dataset. The methodical hyperparameter tuning via GridSearchCV contributed significantly to ensuring not just the accuracy but also the generalizability of the model, making it a robust advancement over the simpler baseline approach.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:36:28.662099Z",
     "start_time": "2019-10-31T23:36:28.660016Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'regressor__max_depth': 20, 'regressor__n_estimators': 100},\n",
       " 1068.7569739778512,\n",
       " 1188.4303926826922)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned = df_cleaned.dropna()\n",
    "X_full = df_cleaned.drop('OUTAGE.DURATION', axis=1)\n",
    "y_full = df_cleaned['OUTAGE.DURATION']\n",
    "#Same random state and proportin as baseline model\n",
    "X_train_full, X_test_full, y_train_full, y_test_full = train_test_split(X_full, y_full, \n",
    "                                                                        test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "all_feature_transform = ColumnTransformer([\n",
    "    ('one_hot_encoder', OneHotEncoder(handle_unknown='ignore'), ['U.S._STATE', 'CLIMATE.CATEGORY', \n",
    "                                          'CAUSE.CATEGORY', 'CAUSE.CATEGORY.DETAIL', 'SEASON']),\n",
    "    ('scaler', StandardScaler(), ['ANOMALY.LEVEL', 'CUSTOMERS.AFFECTED', 'RES.PRICE'])\n",
    "], remainder='passthrough')\n",
    "\n",
    "final_pipeline = Pipeline([\n",
    "    ('transformer', all_feature_transform),\n",
    "    ('regressor', RandomForestRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "param_grid_all_features = {\n",
    "    'regressor__n_estimators': [10, 50, 100],\n",
    "    'regressor__max_depth': [None, 10, 20, 30]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(final_pipeline, \n",
    "                        param_grid_all_features, cv=5, \n",
    "                        scoring='neg_mean_absolute_error', verbose=1)\n",
    "\n",
    "grid_search.fit(X_train_full, y_train_full)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "final_pipeline.set_params(**best_params)\n",
    "final_pipeline.fit(X_full, y_full)\n",
    "\n",
    "train_score = mean_absolute_error(y_train_full, final_pipeline.predict(X_train_full))\n",
    "test_score = mean_absolute_error(y_test_full, final_pipeline.predict(X_test_full))\n",
    "\n",
    "best_params, train_score, test_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fairness Analysis of the Final Model\n",
    "\n",
    "### Groups Definition\n",
    "- **Group X**: Power outages caused by severe weather.\n",
    "- **Group Y**: Power outages due to other reasons.\n",
    "\n",
    "\n",
    "### Hypotheses\n",
    "- **Null Hypothesis**: The model is fair. The MAE for Group X (severe weather) and Group Y (other causes) is roughly the same, with any differences being due to random chance.\n",
    "- **Alternative Hypothesis**: The model is unfair. The MAE for Group X differs significantly from that of Group Y.\n",
    "\n",
    "### Test Statistic and Significance Level\n",
    "- **Test Statistic**: Absolute difference in MAE between Group X and Group Y.\n",
    "- **Significance Level**: 0.05\n",
    "\n",
    "\n",
    "### Results\n",
    "- **Original MAE Difference**: 246.34\n",
    "- **Mean of Permutation MAE Differences**: 300.50\n",
    "- **P-Value**: 0.505\n",
    "\n",
    "### Conclusion\n",
    "The p-value of 0.505 suggests that there is insufficient evidence to reject the null hypothesis. This indicates that the model's performance, as measured by MAE, does not significantly differ between Group X (severe weather-related outages) and Group Y (outages due to other reasons). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:36:28.666489Z",
     "start_time": "2019-10-31T23:36:28.664381Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(246.3364860359859, 300.5000246110856, 0.505)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_X = df_cleaned[df_cleaned['CAUSE.CATEGORY'] == 'severe weather']\n",
    "group_Y = df_cleaned[df_cleaned['CAUSE.CATEGORY'] != 'severe weather']\n",
    "\n",
    "y_X = group_X['OUTAGE.DURATION']\n",
    "X_X = group_X.drop('OUTAGE.DURATION', axis=1)\n",
    "\n",
    "y_Y = group_Y['OUTAGE.DURATION']\n",
    "X_Y = group_Y.drop('OUTAGE.DURATION', axis=1)\n",
    "\n",
    "\n",
    "mae_X = np.abs(y_X-final_pipeline.predict(X_X))\n",
    "mae_Y = np.abs(y_Y-final_pipeline.predict(X_Y))\n",
    "original_mae_diff = abs(mae_X.mean() - mae_Y.mean())\n",
    "combined_mae = np.concatenate((mae_X, mae_Y))\n",
    "n_permutations = 1000\n",
    "mae_diffs = []\n",
    "\n",
    "for _ in range(n_permutations):\n",
    "    np.random.shuffle(combined_mae)\n",
    "    shuffled_y_X = combined_mae[:len(y_X)]\n",
    "    shuffled_y_Y = combined_mae[len(y_X):]\n",
    "\n",
    "    mae_diffs.append(abs(shuffled_y_X.mean() - shuffled_y_Y.mean()))\n",
    "\n",
    "p_value = np.sum(mae_diffs >= original_mae_diff) / n_permutations\n",
    "original_mae_diff,sum(mae_diffs)/len(mae_diffs), p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
